{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclistic Share Case Study\n",
    "![\"\"](Cyclistic_Bike_Share.jpg)\n",
    "## How Does a Bike-Share Navigate Speedy Success?\n",
    "- ### **Scenario**\n",
    "You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve your recommendations, so they must be backed up with compelling data insights and professional data visualizations.\n",
    "\n",
    "- ### **Characters and Teams**\n",
    "    - Cyclistic: A bike-share program that features more than 5,800 bicycles and 600 docking stations. Cyclistic sets itself apart by also offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can’t use a standard two-wheeled bike. The majority of riders opt for traditional bikes; about 8% of riders use the assistive options. Cyclistic users are more likely to ride for leisure, but about 30% use them to commute to work each day.\n",
    "\n",
    "    - Lily Moreno: The director of marketing and your manager. Moreno is responsible for the development of campaigns and initiatives to promote the bike-share program. These may include email, social media, and other channels.\n",
    "    \n",
    "    - Cyclistic marketing analytics team: A team of data analysts who are responsible for collecting, analysing, and reporting data that helps guide Cyclistic marketing strategy. You joined this team six months ago and have been busy learning about Cyclistic’s mission and business goals — as well as how you, as a junior data analyst, can help Cyclistic achieve them.\n",
    "\n",
    "    - Cyclistic executive team: The notoriously detail-oriented executive team will decide whether to approve the recommended marketing program.\n",
    "\n",
    "- ### **About the company**\n",
    "In 2016, Cyclistic launched a successful bike-share offering. Since then, the program has grown to a fleet of 5,824 bicycles that are geotracked and locked into a network of 692 stations across Chicago. The bikes can be unlocked from one station and returned to any other station in the system anytime.\n",
    "\n",
    "Until now, Cyclistic’s marketing strategy relied on building general awareness and appealing to broad consumer segments. One approach that helped make these things possible was the flexibility of its pricing plans: single-ride passes, full-day passes,\n",
    "and annual memberships. Customers who purchase single-ride or full-day passes are referred to as casual riders. Customers who purchase annual memberships are Cyclistic members.\n",
    "\n",
    "Cyclistic’s finance analysts have concluded that annual members are much more profitable than casual riders. Although the pricing flexibility helps Cyclistic attract more customers, Moreno believes that maximizing the number of annual members will be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a very good chance to convert casual riders into members. She notes that casual riders are already aware of the Cyclistic\n",
    "program and have chosen Cyclistic for their mobility needs.\n",
    "\n",
    "Moreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members. In order to do that, however, the marketing analyst team needs to better understand how annual members and casual riders differ, why\n",
    "casual riders would buy a membership, and how digital media could affect their marketing tactics. Moreno and her team are interested in analysing the Cyclistic historical bike trip data to identify trends.\n",
    "\n",
    "\n",
    "We will go through 6 phases of data analysis process\n",
    "\n",
    "## **Ask**\n",
    "Three questions will guide the future marketing program:\n",
    "1. How do annual members and casual riders use Cyclistic bikes differently?\n",
    "1. Why would casual riders buy Cyclistic annual memberships?\n",
    "1. How can Cyclistic use digital media to influence casual riders to become members?\n",
    "\n",
    "Moreno has assigned you the first question to answer:\n",
    "How do annual members and casual riders use Cyclistic bikes differently?\n",
    "\n",
    "\n",
    "#### **What is the problem I am trying to solve?**\n",
    "\n",
    "Right now, this company focuses on broad customer segments and build general awareness. However, for the future profitable growth, the company targets turning casual riders into annual members rather than creating a new marketing campaign targeting all-new-customers. \n",
    "-\tWhy do they launch a new marketing campaign to target the existing customers instead of all-new-customers.\n",
    "    -\tFinance analyst concluded that annual members are much more profitable than casual riders.\n",
    "-\tWhy is annual riders more profitable?\n",
    "    - Maybe targeting on all-new-customers could not increase the number of new users anymore, so targeting on existing customers is more likely to gain profits. \n",
    "-\tWhy is targeting on existing customers better?\n",
    "    - They are probably living around this area and use this service for the daily commuting purpose. If they are around this area, there is more chance that they will change to annual members. \n",
    "-   Why are there more chance?\n",
    "    - In the big city, it will be more convinient to use bicycles to move around. If each station is located at convinient places, more local casual riders want to switch the membership to annual members.\n",
    "\n",
    "##### **How can my insights drive business decisions?**\n",
    "\n",
    "My insight can help Cyclistic evaluate promoting a new campaign for casual riders can be more effective and profitable than promoting a new campaign for all-new-customers like how it was before.\n",
    "\n",
    "##### **A business task:**\n",
    "\n",
    "Find and Compare patterns in annual riders and casual riders to see if a new campaign turning casual riders into annual members works more profitably.\n",
    "\n",
    "##### **Key stakeholders**\n",
    "- Primary Stakeholders\n",
    "    -\tLily Moreno, Cyclistic Executive Team\n",
    "- Secondary Stakeholders\n",
    "    -\tCyclistic, Cyclistic Marketing Analytics Team \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prepare&Process**\n",
    "\n",
    "The data is located at [Index of bucket “divvy-tripdata”](https://divvy-tripdata.s3.amazonaws.com/index.html), and it contains trip_data from 2013-2022. This data gathers information from all users about how different customer types are using Cyclistic bike (e.g., rider_id, bicycle type, start and end time, start and end station, start and end station_id, start and end location coordination, member status). The data is less likely to be biased because it represents a whole rider, usage time, locations via geotracking. This data is owned by The City of Chicago under [this license](https://ride.divvybikes.com/data-license-agreement) and collected by this company’s first hand. The problem is that sometimes this geotracking system does not work, so some columns have null values. For the historical patterns like increasing of annual members, we will use data from 2013-2022. For the recent trend, we will use data from 2020-2022. We will download all data from the above link and save them on local storage based on the collected year.\n",
    "\n",
    "![\"\"](folder_order.jpg)\n",
    "\n",
    "\n",
    "Some data is totally separated into a quarter or a month, so I will concatenate datasets into one dataset based on a year such as “Divvy_Trips_2014.csv.”\n",
    "Here is an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will concatenate and organize 2014_data.\n",
    "\n",
    "First, we will import glob to select all files with the specific name and pandas to organize and clean data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will extract all data with the name \"Divvy_Trips_2014\" under the specific path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=glob.glob(\"Trip_Dataset\\data_2014\\Divvy_Trips_2014*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will concatenate all datasets in the one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "for path in files:\n",
    "    dataset=pd.read_csv(path)\n",
    "    data=pd.concat([data,dataset],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the total length of each data matches with the length of new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2454634 2454634\n"
     ]
    }
   ],
   "source": [
    "length=0\n",
    "for path in files:\n",
    "    length+=len(pd.read_csv(path))\n",
    "print(length, len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is perfectly successed. Let's take a look at data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trip_id              2454634\n",
      "starttime            2454634\n",
      "stoptime             2454634\n",
      "bikeid               2454634\n",
      "tripduration         2454634\n",
      "from_station_id      2454634\n",
      "from_station_name    2454634\n",
      "to_station_id        2454634\n",
      "to_station_name      2454634\n",
      "usertype             2454634\n",
      "gender               1663354\n",
      "birthyear            1663418\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2454634 entries, 0 to 905698\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   trip_id            int64  \n",
      " 1   starttime          object \n",
      " 2   stoptime           object \n",
      " 3   bikeid             int64  \n",
      " 4   tripduration       int64  \n",
      " 5   from_station_id    int64  \n",
      " 6   from_station_name  object \n",
      " 7   to_station_id      int64  \n",
      " 8   to_station_name    object \n",
      " 9   usertype           object \n",
      " 10  gender             object \n",
      " 11  birthyear          float64\n",
      "dtypes: float64(1), int64(5), object(6)\n",
      "memory usage: 243.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All columns, except \"gender\" and \"birthyear\", have 2454634 entries, which means no missing entries.\n",
    "\n",
    "The missing type of missing data in gender and birthyear columns is considered as Missing Not at Random(MNAR) because cyclists probably did not fill in these fields with reasons. Therefore, we will just leave it for now and inspect later.\n",
    "\n",
    "However, to check if the starttime column properly has data from 2014-01-01 to 2014-12-31, we will change the data type of starttime and stoptime and sort it by starttime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"starttime\"]=pd.to_datetime(data[\"starttime\"])\n",
    "data[\"stoptime\"]=pd.to_datetime(data[\"stoptime\"])\n",
    "data.sort_values(by='starttime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>905698</th>\n",
       "      <td>1109420</td>\n",
       "      <td>2014-01-01 00:17:00</td>\n",
       "      <td>2014-01-01 00:42:00</td>\n",
       "      <td>2981</td>\n",
       "      <td>1466</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>69</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905697</th>\n",
       "      <td>1109421</td>\n",
       "      <td>2014-01-01 00:45:00</td>\n",
       "      <td>2014-01-01 00:55:00</td>\n",
       "      <td>2981</td>\n",
       "      <td>608</td>\n",
       "      <td>69</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>216</td>\n",
       "      <td>California Ave &amp; Division St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905696</th>\n",
       "      <td>1109427</td>\n",
       "      <td>2014-01-01 01:12:00</td>\n",
       "      <td>2014-01-01 01:18:00</td>\n",
       "      <td>1818</td>\n",
       "      <td>346</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>245</td>\n",
       "      <td>Clarendon Ave &amp; Junior Ter</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905695</th>\n",
       "      <td>1109431</td>\n",
       "      <td>2014-01-01 01:43:00</td>\n",
       "      <td>2014-01-01 01:53:00</td>\n",
       "      <td>348</td>\n",
       "      <td>650</td>\n",
       "      <td>113</td>\n",
       "      <td>Bissell St &amp; Armitage Ave</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905694</th>\n",
       "      <td>1109432</td>\n",
       "      <td>2014-01-01 01:43:00</td>\n",
       "      <td>2014-01-01 01:53:00</td>\n",
       "      <td>823</td>\n",
       "      <td>652</td>\n",
       "      <td>113</td>\n",
       "      <td>Bissell St &amp; Armitage Ave</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4413163</td>\n",
       "      <td>2014-12-31 23:44:00</td>\n",
       "      <td>2015-01-01 00:10:00</td>\n",
       "      <td>389</td>\n",
       "      <td>1570</td>\n",
       "      <td>43</td>\n",
       "      <td>Michigan Ave &amp; Washington St</td>\n",
       "      <td>163</td>\n",
       "      <td>Damen Ave &amp; Clybourn Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4413164</td>\n",
       "      <td>2014-12-31 23:46:00</td>\n",
       "      <td>2015-01-01 00:37:00</td>\n",
       "      <td>2563</td>\n",
       "      <td>3084</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4413165</td>\n",
       "      <td>2014-12-31 23:48:00</td>\n",
       "      <td>2015-01-01 00:38:00</td>\n",
       "      <td>1946</td>\n",
       "      <td>3002</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4413166</td>\n",
       "      <td>2014-12-31 23:50:00</td>\n",
       "      <td>2014-12-31 23:52:00</td>\n",
       "      <td>1153</td>\n",
       "      <td>161</td>\n",
       "      <td>264</td>\n",
       "      <td>Stetson Ave &amp; South Water St</td>\n",
       "      <td>44</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4413167</td>\n",
       "      <td>2014-12-31 23:54:00</td>\n",
       "      <td>2014-12-31 23:57:00</td>\n",
       "      <td>1880</td>\n",
       "      <td>193</td>\n",
       "      <td>296</td>\n",
       "      <td>Broadway &amp; Belmont Ave</td>\n",
       "      <td>334</td>\n",
       "      <td>Lake Shore Dr &amp; Belmont Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454634 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        trip_id           starttime            stoptime  bikeid  tripduration  \\\n",
       "905698  1109420 2014-01-01 00:17:00 2014-01-01 00:42:00    2981          1466   \n",
       "905697  1109421 2014-01-01 00:45:00 2014-01-01 00:55:00    2981           608   \n",
       "905696  1109427 2014-01-01 01:12:00 2014-01-01 01:18:00    1818           346   \n",
       "905695  1109431 2014-01-01 01:43:00 2014-01-01 01:53:00     348           650   \n",
       "905694  1109432 2014-01-01 01:43:00 2014-01-01 01:53:00     823           652   \n",
       "...         ...                 ...                 ...     ...           ...   \n",
       "4       4413163 2014-12-31 23:44:00 2015-01-01 00:10:00     389          1570   \n",
       "3       4413164 2014-12-31 23:46:00 2015-01-01 00:37:00    2563          3084   \n",
       "2       4413165 2014-12-31 23:48:00 2015-01-01 00:38:00    1946          3002   \n",
       "1       4413166 2014-12-31 23:50:00 2014-12-31 23:52:00    1153           161   \n",
       "0       4413167 2014-12-31 23:54:00 2014-12-31 23:57:00    1880           193   \n",
       "\n",
       "        from_station_id             from_station_name  to_station_id  \\\n",
       "905698               94       Clark St & Armitage Ave             69   \n",
       "905697               69        Damen Ave & Pierce Ave            216   \n",
       "905696              240  Sheridan Rd & Irving Park Rd            245   \n",
       "905695              113     Bissell St & Armitage Ave             94   \n",
       "905694              113     Bissell St & Armitage Ave             94   \n",
       "...                 ...                           ...            ...   \n",
       "4                    43  Michigan Ave & Washington St            163   \n",
       "3                   168        Michigan Ave & 14th St            168   \n",
       "2                   168        Michigan Ave & 14th St            168   \n",
       "1                   264  Stetson Ave & South Water St             44   \n",
       "0                   296        Broadway & Belmont Ave            334   \n",
       "\n",
       "                     to_station_name    usertype gender  birthyear  \n",
       "905698        Damen Ave & Pierce Ave    Customer    NaN        NaN  \n",
       "905697  California Ave & Division St    Customer    NaN        NaN  \n",
       "905696    Clarendon Ave & Junior Ter  Subscriber   Male     1961.0  \n",
       "905695       Clark St & Armitage Ave  Subscriber   Male     1988.0  \n",
       "905694       Clark St & Armitage Ave  Subscriber   Male     1988.0  \n",
       "...                              ...         ...    ...        ...  \n",
       "4           Damen Ave & Clybourn Ave  Subscriber   Male     1983.0  \n",
       "3             Michigan Ave & 14th St  Subscriber   Male     1987.0  \n",
       "2             Michigan Ave & 14th St    Customer    NaN        NaN  \n",
       "1             State St & Randolph St  Subscriber   Male     1984.0  \n",
       "0        Lake Shore Dr & Belmont Ave  Subscriber   Male     1989.0  \n",
       "\n",
       "[2454634 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, starttaime starts from 2014-01-01 to 2014-12-31. This is perfectly sorted. We will save this to csv file under the same path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"Trip_Dataset\\data_2014\\Divvy_Trips_2014.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the data is correctly stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"Trip_Dataset\\data_2014\\Divvy_Trips_2014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1109420</td>\n",
       "      <td>2014-01-01 00:17:00</td>\n",
       "      <td>2014-01-01 00:42:00</td>\n",
       "      <td>2981</td>\n",
       "      <td>1466</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>69</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1109421</td>\n",
       "      <td>2014-01-01 00:45:00</td>\n",
       "      <td>2014-01-01 00:55:00</td>\n",
       "      <td>2981</td>\n",
       "      <td>608</td>\n",
       "      <td>69</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>216</td>\n",
       "      <td>California Ave &amp; Division St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1109427</td>\n",
       "      <td>2014-01-01 01:12:00</td>\n",
       "      <td>2014-01-01 01:18:00</td>\n",
       "      <td>1818</td>\n",
       "      <td>346</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>245</td>\n",
       "      <td>Clarendon Ave &amp; Junior Ter</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1109431</td>\n",
       "      <td>2014-01-01 01:43:00</td>\n",
       "      <td>2014-01-01 01:53:00</td>\n",
       "      <td>348</td>\n",
       "      <td>650</td>\n",
       "      <td>113</td>\n",
       "      <td>Bissell St &amp; Armitage Ave</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1109432</td>\n",
       "      <td>2014-01-01 01:43:00</td>\n",
       "      <td>2014-01-01 01:53:00</td>\n",
       "      <td>823</td>\n",
       "      <td>652</td>\n",
       "      <td>113</td>\n",
       "      <td>Bissell St &amp; Armitage Ave</td>\n",
       "      <td>94</td>\n",
       "      <td>Clark St &amp; Armitage Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454629</th>\n",
       "      <td>4413163</td>\n",
       "      <td>2014-12-31 23:44:00</td>\n",
       "      <td>2015-01-01 00:10:00</td>\n",
       "      <td>389</td>\n",
       "      <td>1570</td>\n",
       "      <td>43</td>\n",
       "      <td>Michigan Ave &amp; Washington St</td>\n",
       "      <td>163</td>\n",
       "      <td>Damen Ave &amp; Clybourn Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1983.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454630</th>\n",
       "      <td>4413164</td>\n",
       "      <td>2014-12-31 23:46:00</td>\n",
       "      <td>2015-01-01 00:37:00</td>\n",
       "      <td>2563</td>\n",
       "      <td>3084</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1987.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454631</th>\n",
       "      <td>4413165</td>\n",
       "      <td>2014-12-31 23:48:00</td>\n",
       "      <td>2015-01-01 00:38:00</td>\n",
       "      <td>1946</td>\n",
       "      <td>3002</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>168</td>\n",
       "      <td>Michigan Ave &amp; 14th St</td>\n",
       "      <td>Customer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454632</th>\n",
       "      <td>4413166</td>\n",
       "      <td>2014-12-31 23:50:00</td>\n",
       "      <td>2014-12-31 23:52:00</td>\n",
       "      <td>1153</td>\n",
       "      <td>161</td>\n",
       "      <td>264</td>\n",
       "      <td>Stetson Ave &amp; South Water St</td>\n",
       "      <td>44</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454633</th>\n",
       "      <td>4413167</td>\n",
       "      <td>2014-12-31 23:54:00</td>\n",
       "      <td>2014-12-31 23:57:00</td>\n",
       "      <td>1880</td>\n",
       "      <td>193</td>\n",
       "      <td>296</td>\n",
       "      <td>Broadway &amp; Belmont Ave</td>\n",
       "      <td>334</td>\n",
       "      <td>Lake Shore Dr &amp; Belmont Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454634 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_id            starttime             stoptime  bikeid  \\\n",
       "0        1109420  2014-01-01 00:17:00  2014-01-01 00:42:00    2981   \n",
       "1        1109421  2014-01-01 00:45:00  2014-01-01 00:55:00    2981   \n",
       "2        1109427  2014-01-01 01:12:00  2014-01-01 01:18:00    1818   \n",
       "3        1109431  2014-01-01 01:43:00  2014-01-01 01:53:00     348   \n",
       "4        1109432  2014-01-01 01:43:00  2014-01-01 01:53:00     823   \n",
       "...          ...                  ...                  ...     ...   \n",
       "2454629  4413163  2014-12-31 23:44:00  2015-01-01 00:10:00     389   \n",
       "2454630  4413164  2014-12-31 23:46:00  2015-01-01 00:37:00    2563   \n",
       "2454631  4413165  2014-12-31 23:48:00  2015-01-01 00:38:00    1946   \n",
       "2454632  4413166  2014-12-31 23:50:00  2014-12-31 23:52:00    1153   \n",
       "2454633  4413167  2014-12-31 23:54:00  2014-12-31 23:57:00    1880   \n",
       "\n",
       "         tripduration  from_station_id             from_station_name  \\\n",
       "0                1466               94       Clark St & Armitage Ave   \n",
       "1                 608               69        Damen Ave & Pierce Ave   \n",
       "2                 346              240  Sheridan Rd & Irving Park Rd   \n",
       "3                 650              113     Bissell St & Armitage Ave   \n",
       "4                 652              113     Bissell St & Armitage Ave   \n",
       "...               ...              ...                           ...   \n",
       "2454629          1570               43  Michigan Ave & Washington St   \n",
       "2454630          3084              168        Michigan Ave & 14th St   \n",
       "2454631          3002              168        Michigan Ave & 14th St   \n",
       "2454632           161              264  Stetson Ave & South Water St   \n",
       "2454633           193              296        Broadway & Belmont Ave   \n",
       "\n",
       "         to_station_id               to_station_name    usertype gender  \\\n",
       "0                   69        Damen Ave & Pierce Ave    Customer    NaN   \n",
       "1                  216  California Ave & Division St    Customer    NaN   \n",
       "2                  245    Clarendon Ave & Junior Ter  Subscriber   Male   \n",
       "3                   94       Clark St & Armitage Ave  Subscriber   Male   \n",
       "4                   94       Clark St & Armitage Ave  Subscriber   Male   \n",
       "...                ...                           ...         ...    ...   \n",
       "2454629            163      Damen Ave & Clybourn Ave  Subscriber   Male   \n",
       "2454630            168        Michigan Ave & 14th St  Subscriber   Male   \n",
       "2454631            168        Michigan Ave & 14th St    Customer    NaN   \n",
       "2454632             44        State St & Randolph St  Subscriber   Male   \n",
       "2454633            334   Lake Shore Dr & Belmont Ave  Subscriber   Male   \n",
       "\n",
       "         birthyear  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2           1961.0  \n",
       "3           1988.0  \n",
       "4           1988.0  \n",
       "...            ...  \n",
       "2454629     1983.0  \n",
       "2454630     1987.0  \n",
       "2454631        NaN  \n",
       "2454632     1984.0  \n",
       "2454633     1989.0  \n",
       "\n",
       "[2454634 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for 2014 is stored into one file corractly and sorted by starttime properly.\n",
    "\n",
    "The preparation step for 2014 is done.\n",
    "\n",
    "We will automate all this process with the function below and organize all data. Save all into \"Concat_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation():\n",
    "    year=2013\n",
    "    while year < 2023:\n",
    "        select_path=\"Trip_Dataset\\data_\"+str(year)+\"\\*\"\n",
    "        \n",
    "        files=glob.glob(select_path)\n",
    "        data_trips=pd.DataFrame()\n",
    "        data_stations=pd.DataFrame()\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            if \"trip\" in file.split('\\\\')[2].lower():\n",
    "                print(file + \" contains trip\")\n",
    "                if file.split(\".\")[1]==\"csv\":\n",
    "                    dataset=pd.read_csv(file)\n",
    "                elif file.split('.')[1]==\"xlsx\":\n",
    "                    dataset=pd.read_excel(file)\n",
    "                data_trips=pd.concat([data_trips, dataset],axis=0)\n",
    "\n",
    "            elif \"station\" in file.split('\\\\')[2].lower():\n",
    "                print(file + \" contains station\")\n",
    "                if file.split(\".\")[1]==\"csv\":\n",
    "                    dataset=pd.read_csv(file)\n",
    "                elif file.split('.')[1]==\"xlsx\":\n",
    "                    dataset=pd.read_excel(file)\n",
    "                data_stations=pd.concat([data_stations,dataset], axis=0)\n",
    "        storing_trips_path=os.path.join(\"Concat_Data\",\"Divvy_Trips_\"+str(year))\n",
    "        storing_stations_path=os.path.join('Concat_Data',\"Divvy_Stations_\"+str(year))\n",
    "        if not data_trips.empty:\n",
    "            if os.path.exists(storing_trips_path+\".csv\")==False:\n",
    "                data_trips.to_csv(storing_trips_path+\".csv\", index=False)\n",
    "                print(storing_trips_path+\".csv is added\")\n",
    "        if not data_stations.empty:\n",
    "            if os.path.exists(storing_stations_path+\".csv\")==False:\n",
    "                data_stations.to_csv(storing_stations_path+\".csv\", index=False)\n",
    "                print(storing_stations_path+\".csv is added\")\n",
    "        year+=1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_Dataset\\data_2013\\Divvy_Stations_2013.csv contains station\n",
      "Trip_Dataset\\data_2013\\Divvy_Trips_2013.csv contains trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_10104\\4047910637.py:15: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip_Dataset\\data_2014\\Divvy_Stations_2014-Q1Q2.xlsx contains station\n",
      "Trip_Dataset\\data_2014\\Divvy_Stations_2014-Q3Q4.csv contains station\n",
      "Trip_Dataset\\data_2014\\Divvy_Trips_2014-Q3-07.csv contains trip\n",
      "Trip_Dataset\\data_2014\\Divvy_Trips_2014-Q3-0809.csv contains trip\n",
      "Trip_Dataset\\data_2014\\Divvy_Trips_2014-Q4.csv contains trip\n",
      "Trip_Dataset\\data_2014\\Divvy_Trips_2014.csv contains trip\n",
      "Trip_Dataset\\data_2014\\Divvy_Trips_2014_Q1Q2.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Stations_2015.csv contains station\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015-Q1.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015-Q2.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015_07.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015_08.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015_09.csv contains trip\n",
      "Trip_Dataset\\data_2015\\Divvy_Trips_2015_Q4.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Stations_2016_Q1Q2.csv contains station\n",
      "Trip_Dataset\\data_2016\\Divvy_Stations_2016_Q3.csv contains station\n",
      "Trip_Dataset\\data_2016\\Divvy_Stations_2016_Q4.csv contains station\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_04.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_05.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_06.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_Q1.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_Q3.csv contains trip\n",
      "Trip_Dataset\\data_2016\\Divvy_Trips_2016_Q4.csv contains trip\n",
      "Trip_Dataset\\data_2017\\Divvy_Stations_2017_Q1Q2.csv contains station\n",
      "Trip_Dataset\\data_2017\\Divvy_Stations_2017_Q3Q4.csv contains station\n",
      "Trip_Dataset\\data_2017\\Divvy_Trips_2017_Q1.csv contains trip\n",
      "Trip_Dataset\\data_2017\\Divvy_Trips_2017_Q2.csv contains trip\n",
      "Trip_Dataset\\data_2017\\Divvy_Trips_2017_Q3.csv contains trip\n",
      "Trip_Dataset\\data_2017\\Divvy_Trips_2017_Q4.csv contains trip\n",
      "Trip_Dataset\\data_2018\\Divvy_Trips_2018_Q1.csv contains trip\n",
      "Trip_Dataset\\data_2018\\Divvy_Trips_2018_Q2.csv contains trip\n",
      "Trip_Dataset\\data_2018\\Divvy_Trips_2018_Q3.csv contains trip\n",
      "Trip_Dataset\\data_2018\\Divvy_Trips_2018_Q4.csv contains trip\n",
      "Trip_Dataset\\data_2019\\Divvy_Trips_2019_Q1.csv contains trip\n",
      "Trip_Dataset\\data_2019\\Divvy_Trips_2019_Q2.csv contains trip\n",
      "Trip_Dataset\\data_2019\\Divvy_Trips_2019_Q3.csv contains trip\n",
      "Trip_Dataset\\data_2019\\Divvy_Trips_2019_Q4.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202004-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202005-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202006-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202007-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202008-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202009-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202010-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202011-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\202012-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2020\\Divvy_Trips_2020_Q1.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202101-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202102-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202103-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202104-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202105-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202106-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202107-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202108-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202109-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202110-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202111-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2021\\202112-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202201-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202202-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202203-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202204-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202205-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202206-divvy-tripdata.csv contains trip\n",
      "Trip_Dataset\\data_2022\\202207-divvy-tripdata.csv contains trip\n"
     ]
    }
   ],
   "source": [
    "data_preparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the data is correctly stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2454634 2454634\n"
     ]
    }
   ],
   "source": [
    "dataset1=pd.read_csv(\"Concat_Data\\Divvy_Trips_2014.csv\")\n",
    "print(len(dataset), len(dataset1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see data is successfully concatenated. As we can see below, Trips dataset is from 2013-2022, whereas Stations dataset is from 2013-2017.\n",
    "\n",
    "![\"\"](after_concat.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I run display(csv_file), I find some data has wrong columns when it is concatnated. I will fix them so that all could have been prepared correctly.\n",
    "\n",
    "- Modifying coulmns of Trip_Dataset\\data_2018\\Divvy_Trips_2018_Q1.csv and Trip_Dataset\\data_2019\\Divvy_Trips_2019_Q2.csv corresponding to other data columns.\n",
    "\n",
    "#### Trips Data\n",
    "- All trips_data contains start time and end time, but columns are not unified. We will modify the column names to \"starttime\" and \"stoptime\".\n",
    "- Also, \"starttime\" and \"stoptime\" are time, so we will change data type to datetime.\n",
    "- Moreover, tripduration can be converted into int64 instead of object type if there is no missing data.\n",
    "- From 2013 to 2019, there is no missing data except gender and birthyear column. As I mentioned before, this is Missing Not at Random(MNAR) because there could be reasons behind this missing data. We will leave missing values.\n",
    "- From 2020 to 2022, station name, id, longtitude, and latitude columns from start and end station are missing. We cannot fill all of missing data, but we will not drop rows with missing data because each row still contains useful information. We will try to find the start station name and id from start longtitude and latitude and find the end station name and id from end longtitude and latitude.\n",
    "- We will add a tripduration column to dataset from 2020 to 2022.\n",
    "- From starttime and stoptime, we will find the days of the week of usage and a month of usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divvy_trips_2013.csv contains trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1765331982.py:8: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_data[year]=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: Concat_Data\\Divvy_Trips_2013.csv is added to trips_data\n",
      "divvy_trips_2014.csv contains trip\n",
      "2014: Concat_Data\\Divvy_Trips_2014.csv is added to trips_data\n",
      "divvy_trips_2015.csv contains trip\n",
      "2015: Concat_Data\\Divvy_Trips_2015.csv is added to trips_data\n",
      "divvy_trips_2016.csv contains trip\n",
      "2016: Concat_Data\\Divvy_Trips_2016.csv is added to trips_data\n",
      "divvy_trips_2017.csv contains trip\n",
      "2017: Concat_Data\\Divvy_Trips_2017.csv is added to trips_data\n",
      "divvy_trips_2018.csv contains trip\n",
      "2018: Concat_Data\\Divvy_Trips_2018.csv is added to trips_data\n",
      "divvy_trips_2019.csv contains trip\n",
      "2019: Concat_Data\\Divvy_Trips_2019.csv is added to trips_data\n",
      "divvy_trips_2020.csv contains trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1765331982.py:8: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_data[year]=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: Concat_Data\\Divvy_Trips_2020.csv is added to trips_data\n",
      "divvy_trips_2021.csv contains trip\n",
      "2021: Concat_Data\\Divvy_Trips_2021.csv is added to trips_data\n",
      "divvy_trips_2022.csv contains trip\n",
      "2022: Concat_Data\\Divvy_Trips_2022.csv is added to trips_data\n",
      "divvy_stations_2013.csv contains station\n",
      "2013: Concat_Data\\Divvy_Stations_2013.csv is added to stations_data\n",
      "divvy_stations_2014.csv contains station\n",
      "2014: Concat_Data\\Divvy_Stations_2014.csv is added to stations_data\n",
      "divvy_stations_2015.csv contains station\n",
      "2015: Concat_Data\\Divvy_Stations_2015.csv is added to stations_data\n",
      "divvy_stations_2016.csv contains station\n",
      "2016: Concat_Data\\Divvy_Stations_2016.csv is added to stations_data\n",
      "divvy_stations_2017.csv contains station\n",
      "2017: Concat_Data\\Divvy_Stations_2017.csv is added to stations_data\n",
      "dict_keys([2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022])\n",
      "dict_keys([2013, 2014, 2015, 2016, 2017])\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"Concat_Data/*\")\n",
    "trips_data={}\n",
    "stations_data={}\n",
    "year=2013\n",
    "for file in files:\n",
    "    if \"trip\" in file.split(\"\\\\\")[1].lower():\n",
    "        print(file.split(\"\\\\\")[1].lower()+ \" contains trip\")\n",
    "        trips_data[year]=pd.read_csv(file)\n",
    "        print(str(year)+\": \"+file+\" is added to trips_data\")\n",
    "        year+=1\n",
    "year=2013\n",
    "for file in files:\n",
    "    if \"station\" in file.split(\"\\\\\")[1].lower():\n",
    "        print(file.split(\"\\\\\")[1].lower()+ \" contains station\")\n",
    "        stations_data[year]=pd.read_csv(file)\n",
    "        print(str(year)+\": \"+file+\" is added to stations_data\")\n",
    "        year+=1\n",
    "print(trips_data.keys())\n",
    "print(stations_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see some numbers are stored as String. For example, the number was stored like 2,703. I will replce \",\" with \"\", so we can strip it and convert it into numeric type. Then, we will convert it into int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 759788 entries, 0 to 759787\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   trip_id            759788 non-null  int64         \n",
      " 1   starttime          759788 non-null  datetime64[ns]\n",
      " 2   stoptime           759788 non-null  datetime64[ns]\n",
      " 3   bikeid             759788 non-null  int64         \n",
      " 4   tripduration       759788 non-null  int64         \n",
      " 5   from_station_id    759788 non-null  int64         \n",
      " 6   from_station_name  759788 non-null  object        \n",
      " 7   to_station_id      759788 non-null  int64         \n",
      " 8   to_station_name    759788 non-null  object        \n",
      " 9   usertype           759788 non-null  object        \n",
      " 10  gender             403046 non-null  object        \n",
      " 11  birthday           402909 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 69.6+ MB\n",
      "None\n",
      "trip_id              759788\n",
      "starttime            759788\n",
      "stoptime             759788\n",
      "bikeid               759788\n",
      "tripduration         759788\n",
      "from_station_id      759788\n",
      "from_station_name    759788\n",
      "to_station_id        759788\n",
      "to_station_name      759788\n",
      "usertype             759788\n",
      "gender               403046\n",
      "birthday             402909\n",
      "dtype: int64\n",
      "2014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2454634 entries, 0 to 2454633\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 224.7+ MB\n",
      "None\n",
      "trip_id              2454634\n",
      "starttime            2454634\n",
      "stoptime             2454634\n",
      "bikeid               2454634\n",
      "tripduration         2454634\n",
      "from_station_id      2454634\n",
      "from_station_name    2454634\n",
      "to_station_id        2454634\n",
      "to_station_name      2454634\n",
      "usertype             2454634\n",
      "gender               1663354\n",
      "birthyear            1663418\n",
      "dtype: int64\n",
      "2015\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3183439 entries, 0 to 3183438\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 291.5+ MB\n",
      "None\n",
      "trip_id              3183439\n",
      "starttime            3183439\n",
      "stoptime             3183439\n",
      "bikeid               3183439\n",
      "tripduration         3183439\n",
      "from_station_id      3183439\n",
      "from_station_name    3183439\n",
      "to_station_id        3183439\n",
      "to_station_name      3183439\n",
      "usertype             3183439\n",
      "gender               2253468\n",
      "birthyear            2253584\n",
      "dtype: int64\n",
      "2016\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3595383 entries, 0 to 3595382\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 329.2+ MB\n",
      "None\n",
      "trip_id              3595383\n",
      "starttime            3595383\n",
      "stoptime             3595383\n",
      "bikeid               3595383\n",
      "tripduration         3595383\n",
      "from_station_id      3595383\n",
      "from_station_name    3595383\n",
      "to_station_id        3595383\n",
      "to_station_name      3595383\n",
      "usertype             3595383\n",
      "gender               2736954\n",
      "birthyear            2737258\n",
      "dtype: int64\n",
      "2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3829014 entries, 0 to 3829013\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 350.6+ MB\n",
      "None\n",
      "trip_id              3829014\n",
      "starttime            3829014\n",
      "stoptime             3829014\n",
      "bikeid               3829014\n",
      "tripduration         3829014\n",
      "from_station_id      3829014\n",
      "from_station_name    3829014\n",
      "to_station_id        3829014\n",
      "to_station_name      3829014\n",
      "usertype             3829014\n",
      "gender               2992187\n",
      "birthyear            2992256\n",
      "dtype: int64\n",
      "2018\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3603082 entries, 0 to 3603081\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 329.9+ MB\n",
      "None\n",
      "trip_id              3603082\n",
      "starttime            3603082\n",
      "stoptime             3603082\n",
      "bikeid               3603082\n",
      "tripduration         3603082\n",
      "from_station_id      3603082\n",
      "from_station_name    3603082\n",
      "to_station_id        3603082\n",
      "to_station_name      3603082\n",
      "usertype             3603082\n",
      "gender               3040577\n",
      "birthyear            3047873\n",
      "dtype: int64\n",
      "2019\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3818004 entries, 0 to 3818003\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   trip_id            int64         \n",
      " 1   starttime          datetime64[ns]\n",
      " 2   stoptime           datetime64[ns]\n",
      " 3   bikeid             int64         \n",
      " 4   tripduration       int64         \n",
      " 5   from_station_id    int64         \n",
      " 6   from_station_name  object        \n",
      " 7   to_station_id      int64         \n",
      " 8   to_station_name    object        \n",
      " 9   usertype           object        \n",
      " 10  gender             object        \n",
      " 11  birthyear          float64       \n",
      "dtypes: datetime64[ns](2), float64(1), int64(5), object(4)\n",
      "memory usage: 349.5+ MB\n",
      "None\n",
      "trip_id              3818004\n",
      "starttime            3818004\n",
      "stoptime             3818004\n",
      "bikeid               3818004\n",
      "tripduration         3818004\n",
      "from_station_id      3818004\n",
      "from_station_name    3818004\n",
      "to_station_id        3818004\n",
      "to_station_name      3818004\n",
      "usertype             3818004\n",
      "gender               3258798\n",
      "birthyear            3279253\n",
      "dtype: int64\n",
      "2020\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3541683 entries, 0 to 3541682\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   starttime           datetime64[ns]\n",
      " 3   stoptime            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      " 13  tripduration        int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(1), object(7)\n",
      "memory usage: 378.3+ MB\n",
      "None\n",
      "ride_id               3541683\n",
      "rideable_type         3541683\n",
      "starttime             3541683\n",
      "stoptime              3541683\n",
      "start_station_name    3541683\n",
      "start_station_id      3446401\n",
      "end_station_name      3484909\n",
      "end_station_id        3430341\n",
      "start_lat             3541683\n",
      "start_lng             3541683\n",
      "end_lat               3537428\n",
      "end_lng               3537428\n",
      "member_casual         3541683\n",
      "tripduration          3541683\n",
      "dtype: int64\n",
      "2021\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5595063 entries, 0 to 5595062\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   starttime           datetime64[ns]\n",
      " 3   stoptime            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      " 13  tripduration        int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(1), object(7)\n",
      "memory usage: 597.6+ MB\n",
      "None\n",
      "ride_id               5595063\n",
      "rideable_type         5595063\n",
      "starttime             5595063\n",
      "stoptime              5595063\n",
      "start_station_name    5595063\n",
      "start_station_id      4904257\n",
      "end_station_name      5279111\n",
      "end_station_id        4855893\n",
      "start_lat             5595063\n",
      "start_lng             5595063\n",
      "end_lat               5590292\n",
      "end_lng               5590292\n",
      "member_casual         5595063\n",
      "tripduration          5595063\n",
      "dtype: int64\n",
      "2022\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3102220 entries, 0 to 3102219\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   starttime           datetime64[ns]\n",
      " 3   stoptime            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      " 13  tripduration        int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(1), object(7)\n",
      "memory usage: 331.4+ MB\n",
      "None\n",
      "ride_id               3102220\n",
      "rideable_type         3102220\n",
      "starttime             3102220\n",
      "stoptime              3102220\n",
      "start_station_name    3102220\n",
      "start_station_id      2657568\n",
      "end_station_name      2868076\n",
      "end_station_id        2623219\n",
      "start_lat             3102220\n",
      "start_lng             3102220\n",
      "end_lat               3098750\n",
      "end_lng               3098750\n",
      "member_casual         3102220\n",
      "tripduration          3102220\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for key, value in trips_data.items():\n",
    "    print(key)\n",
    "    value.rename(columns={\"start_time\":\"starttime\",\"end_time\":\"stoptime\"}, inplace=True)\n",
    "    value.rename(columns={\"started_at\":\"starttime\",\"ended_at\":\"stoptime\"}, inplace=True)\n",
    "    value.starttime=pd.to_datetime(value.starttime)\n",
    "    value.stoptime=pd.to_datetime(value.stoptime)\n",
    "    if \"tripduration\" in value.columns:\n",
    "        if value.tripduration.dtype!=\"int64\":\n",
    "            value.tripduration=value.tripduration.str.replace(\",\",\"\")\n",
    "            value.tripduration=pd.to_numeric(value.tripduration)\n",
    "            value.tripduration=value.tripduration.astype(np.int64)\n",
    "    print(value.info())\n",
    "    print(value.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill the missing station name from longtitude and latitude.\n",
    "We do not know the specific coordination of each station for 2020-2022 data, so we will find the mean latitude and longtitude for each station. Then, we will assign the closest station name to the unknown value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trip_2020=trips_data[2020]\n",
    "data_trip_2021=trips_data[2021]\n",
    "data_trip_2022=trips_data[2022]\n",
    "\n",
    "\n",
    "trips_from_2020_to_2022=[data_trip_2020,data_trip_2021,data_trip_2022]\n",
    "stations_from_2020_to_2022={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year=2020\n",
    "for i in range(len(trips_from_2020_to_2022)):\n",
    "    data=trips_from_2020_to_2022[i]\n",
    "    start_latitude=data.groupby([\"start_station_name\"]).start_lat.mean()\n",
    "    start_longtitude=data.groupby([\"start_station_name\"]).start_lng.mean()\n",
    "    end_latitude=data.groupby([\"end_station_name\"]).end_lat.mean()\n",
    "    end_longtitude=data.groupby([\"end_station_name\"]).end_lng.mean()\n",
    "    stations={}\n",
    "    for station in start_latitude.index:\n",
    "        if station not in stations.keys():\n",
    "            lat=start_latitude.loc[station]\n",
    "            lng=start_longtitude.loc[station]\n",
    "        else:\n",
    "            lat=(stations[station][0]+start_latitude.loc[station])/2\n",
    "            lng=(stations[station][1]+start_longtitude.loc[station])/2\n",
    "        stations[station]=[lat,lng]\n",
    "\n",
    "    for station in end_latitude.index:\n",
    "        if station not in stations.keys():\n",
    "            lat=end_latitude.loc[station]\n",
    "            lng=end_longtitude.loc[station]\n",
    "        else:\n",
    "            lat=(stations[station][0]+end_latitude.loc[station])/2\n",
    "            lng=(stations[station][1]+end_longtitude.loc[station])/2\n",
    "        stations[station]=[lat,lng]\n",
    "    stations_from_2020_to_2022[year]=stations\n",
    "    year+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two stations only in start_station column and two stations only in end_station column. But, now we have the average coordination of each station in stations_2020 dictionary. \n",
    "\n",
    "\n",
    "We will extract rows with NaN values on start_station_name first and drop rows without start_lng or start_lat because we cannot compute the closest station without these data. This coordination error will take lots of decimals, so the error function will just calculate the absolute values of margin errors from each station.\n",
    "We extract them and save it to \"missing_station_name\" with the key of year, and this will help reducing computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_closest_station(row, year):\n",
    "    closest=row.start_station_name\n",
    "    stations=stations_from_2020_to_2022[year]\n",
    "    if closest is np.nan:\n",
    "        row_lat=row.start_lat\n",
    "        row_lng=row.start_lng\n",
    "        min_error=100\n",
    "        for station in stations:\n",
    "            lat,lng=stations[station]\n",
    "            error=abs(lat-row_lat)+abs(lng-row_lng)\n",
    "            if error<min_error:\n",
    "                closest=station\n",
    "    return closest\n",
    "\n",
    "\n",
    "def end_closest_station(row, year):\n",
    "    closest=row.end_station_name\n",
    "    stations=stations_from_2020_to_2022[year]\n",
    "    if closest is np.nan:\n",
    "        row_lat=row.end_lat\n",
    "        row_lng=row.end_lng\n",
    "        min_error=100\n",
    "        for station in stations:\n",
    "            lat,lng=stations[station]\n",
    "            error=abs(lat-row_lat)+abs(lng-row_lng)\n",
    "            if error<min_error:\n",
    "                closest=station\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply functions for each row and find the closest start station and the closest end station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.dropna(subset=[\"start_lat\",\"start_lng\"], inplace=True)\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.start_station_name=missing_data.apply(start_closest_station, axis=1, year=(year))\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.end_station_name=missing_data.apply(end_closest_station, axis=1, year=(year))\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.dropna(subset=[\"start_lat\",\"start_lng\"], inplace=True)\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.start_station_name=missing_data.apply(start_closest_station, axis=1, year=(year))\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.end_station_name=missing_data.apply(end_closest_station, axis=1, year=(year))\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.dropna(subset=[\"start_lat\",\"start_lng\"], inplace=True)\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.start_station_name=missing_data.apply(start_closest_station, axis=1, year=(year))\n",
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\1407412702.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data.end_station_name=missing_data.apply(end_closest_station, axis=1, year=(year))\n"
     ]
    }
   ],
   "source": [
    "missing_station_name={}\n",
    "year=2020\n",
    "for data in trips_from_2020_to_2022:\n",
    "    missing_data=data[data.start_station_name.isna()]\n",
    "    missing_data.dropna(subset=[\"start_lat\",\"start_lng\"], inplace=True)\n",
    "    missing_data.start_station_name=missing_data.apply(start_closest_station, axis=1, year=(year))\n",
    "    missing_data.end_station_name=missing_data.apply(end_closest_station, axis=1, year=(year))\n",
    "    missing_station_name[year]=missing_data\n",
    "    year+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630367     None\n",
       "642029     None\n",
       "653657     None\n",
       "670853     None\n",
       "670856     None\n",
       "           ... \n",
       "3105966    None\n",
       "3105967    None\n",
       "3105968    None\n",
       "3105969    None\n",
       "3105970    None\n",
       "Length: 94656, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_station_name_dict={}\n",
    "def extract_data_into_dict(row):\n",
    "    missing_station_name_dict[row.ride_id]=[row.start_station_name, row.end_station_name]\n",
    "\n",
    "missing_station_name[2020].apply(extract_data_into_dict, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, functions will help filling dataset corresponding to missing_station_name, and we will replace the dataset with newly filled dataset.\n",
    "We will overwrite old datasets with new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_NaN(row):\n",
    "    if row.isnull().start_station_name:\n",
    "        if row.notnull().start_lng:\n",
    "            row.start_station_name, row.end_station_name=missing_station_name_dict[row.ride_id]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_station_name_dict={}\n",
    "missing_station_name[2020].apply(extract_data_into_dict, axis=1)\n",
    "data_2020=trips_from_2020_to_2022[0]\n",
    "filled_Data=data_2020.apply(fill_NaN, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020=filled_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_station_name_dict={}\n",
    "missing_station_name[2021].apply(extract_data_into_dict, axis=1)\n",
    "data_2021=trips_from_2020_to_2022[1]\n",
    "filled_Data=data_2021.apply(fill_NaN, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021=filled_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_station_name_dict={}\n",
    "missing_station_name[2022].apply(extract_data_into_dict, axis=1)\n",
    "data_2022=trips_from_2020_to_2022[2]\n",
    "filled_Data=data_2022.apply(fill_NaN, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022=filled_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020.to_csv(\"Concat_Data\\Divvy_Trips_2020.csv\", index=False)\n",
    "data_2021.to_csv(\"Concat_Data\\Divvy_Trips_2021.csv\", index=False)\n",
    "data_2022.to_csv(\"Concat_Data\\Divvy_Trips_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will make a new column \"tripduration\" on datasets from 2020 to 2022 because they do not have it.\n",
    "As I mentioned before, there is no missing values on starttime and stoptime, so we can just substract them.\n",
    "tripduration needs to be in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_duration(row):\n",
    "    return row.stoptime-row.starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020[\"tripduration\"]=data_2020.apply(trip_duration, axis=1)\n",
    "data_2020[\"tripduration\"]=data_2020.tripduration.dt.total_seconds().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2021[\"tripduration\"]=data_2021.apply(trip_duration, axis=1)\n",
    "data_2021[\"tripduration\"]=data_2021.tripduration.dt.total_seconds().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2022[\"tripduration\"]=data_2022.apply(trip_duration, axis=1)\n",
    "data_2022[\"tripduration\"]=data_2022.tripduration.dt.total_seconds().astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020.to_csv(\"Concat_Data\\Divvy_Trips_2020.csv\", index=False)\n",
    "data_2021.to_csv(\"Concat_Data\\Divvy_Trips_2021.csv\", index=False)\n",
    "data_2022.to_csv(\"Concat_Data\\Divvy_Trips_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will add new columns, month and day_of_week, for all datasets.\n",
    "We have updated csv files, so we will update our trips_data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divvy_trips_2013.csv contains trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\4242506183.py:7: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_data[year]=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013: Concat_Data\\Divvy_Trips_2013.csv is added to trips_data\n",
      "divvy_trips_2014.csv contains trip\n",
      "2014: Concat_Data\\Divvy_Trips_2014.csv is added to trips_data\n",
      "divvy_trips_2015.csv contains trip\n",
      "2015: Concat_Data\\Divvy_Trips_2015.csv is added to trips_data\n",
      "divvy_trips_2016.csv contains trip\n",
      "2016: Concat_Data\\Divvy_Trips_2016.csv is added to trips_data\n",
      "divvy_trips_2017.csv contains trip\n",
      "2017: Concat_Data\\Divvy_Trips_2017.csv is added to trips_data\n",
      "divvy_trips_2018.csv contains trip\n",
      "2018: Concat_Data\\Divvy_Trips_2018.csv is added to trips_data\n",
      "divvy_trips_2019.csv contains trip\n",
      "2019: Concat_Data\\Divvy_Trips_2019.csv is added to trips_data\n",
      "divvy_trips_2020.csv contains trip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crane\\AppData\\Local\\Temp\\ipykernel_31720\\4242506183.py:7: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trips_data[year]=pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020: Concat_Data\\Divvy_Trips_2020.csv is added to trips_data\n",
      "divvy_trips_2021.csv contains trip\n",
      "2021: Concat_Data\\Divvy_Trips_2021.csv is added to trips_data\n",
      "divvy_trips_2022.csv contains trip\n",
      "2022: Concat_Data\\Divvy_Trips_2022.csv is added to trips_data\n",
      "dict_keys([2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022])\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob(\"Concat_Data/*\")\n",
    "trips_data={}\n",
    "year=2013\n",
    "for file in files:\n",
    "    if \"trip\" in file.split(\"\\\\\")[1].lower():\n",
    "        print(file.split(\"\\\\\")[1].lower()+ \" contains trip\")\n",
    "        trips_data[year]=pd.read_csv(file)\n",
    "        print(str(year)+\": \"+file+\" is added to trips_data\")\n",
    "        year+=1\n",
    "print(trips_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in trips_data.values():\n",
    "    data[\"month\"]=data.starttime.dt.month\n",
    "    data[\"dayofweek\"]=data.starttime.dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Station Data from 2013 to 2017\n",
    "\n",
    "- station data from 2017 has one extra column, so we just drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           300 non-null    int64  \n",
      " 1   name         300 non-null    object \n",
      " 2   latitude     300 non-null    float64\n",
      " 3   longitude    300 non-null    float64\n",
      " 4   dpcapacity   300 non-null    int64  \n",
      " 5   landmark     300 non-null    int64  \n",
      " 6   online date  300 non-null    object \n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 16.5+ KB\n",
      "None\n",
      "id             300\n",
      "name           300\n",
      "latitude       300\n",
      "longitude      300\n",
      "dpcapacity     300\n",
      "landmark       300\n",
      "online date    300\n",
      "dtype: int64\n",
      "2014\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           600 non-null    int64  \n",
      " 1   name         600 non-null    object \n",
      " 2   latitude     600 non-null    float64\n",
      " 3   longitude    600 non-null    float64\n",
      " 4   dpcapacity   600 non-null    int64  \n",
      " 5   online_date  600 non-null    object \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 28.2+ KB\n",
      "None\n",
      "id             600\n",
      "name           600\n",
      "latitude       600\n",
      "longitude      600\n",
      "dpcapacity     600\n",
      "online_date    600\n",
      "dtype: int64\n",
      "2015\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 474 entries, 0 to 473\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   id          474 non-null    int64  \n",
      " 1   name        474 non-null    object \n",
      " 2   latitude    474 non-null    float64\n",
      " 3   longitude   474 non-null    float64\n",
      " 4   dpcapacity  474 non-null    int64  \n",
      " 5   landmark    474 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 22.3+ KB\n",
      "None\n",
      "id            474\n",
      "name          474\n",
      "latitude      474\n",
      "longitude     474\n",
      "dpcapacity    474\n",
      "landmark      474\n",
      "dtype: int64\n",
      "2016\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1697 entries, 0 to 1696\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           1697 non-null   int64  \n",
      " 1   name         1697 non-null   object \n",
      " 2   latitude     1697 non-null   float64\n",
      " 3   longitude    1697 non-null   float64\n",
      " 4   dpcapacity   1697 non-null   int64  \n",
      " 5   online_date  1697 non-null   object \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 79.7+ KB\n",
      "None\n",
      "id             1697\n",
      "name           1697\n",
      "latitude       1697\n",
      "longitude      1697\n",
      "dpcapacity     1697\n",
      "online_date    1697\n",
      "dtype: int64\n",
      "2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167 entries, 0 to 1166\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           1167 non-null   int64  \n",
      " 1   name         1167 non-null   object \n",
      " 2   city         1167 non-null   object \n",
      " 3   latitude     1167 non-null   float64\n",
      " 4   longitude    1167 non-null   float64\n",
      " 5   dpcapacity   1167 non-null   int64  \n",
      " 6   online_date  1167 non-null   object \n",
      " 7   Unnamed: 7   0 non-null      float64\n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 73.1+ KB\n",
      "None\n",
      "id             1167\n",
      "name           1167\n",
      "city           1167\n",
      "latitude       1167\n",
      "longitude      1167\n",
      "dpcapacity     1167\n",
      "online_date    1167\n",
      "Unnamed: 7        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for key, value in stations_data.items():\n",
    "    print(key)\n",
    "    print(value.info())\n",
    "    print(value.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just save all dataset under \"Cleaned_Data\" directory, so we can use them anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "\n",
    "\n",
    "def cleaned_data_to_csv(trips_data, stations_data):\n",
    "    for key, value in trips_data.items():\n",
    "        value.to_csv(\"Cleaned_Data\\Divvy_Trips_\"+str(key)+\".csv\", index=False)\n",
    "    for key, value in stations_data.items():\n",
    "        value.to_csv(\"Cleaned_Data\\Divvy_Stations_\"+str(key)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_to_csv(trips_data, stations_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analyse & Share** \n",
    "Now, we start analyzing the cleaned_data to see what difference casual riders and annual members.\n",
    "\n",
    "We use R for data analysis to create and save visualizations.\n",
    "\n",
    "The code is in the other file.\n",
    "\n",
    "First, we will examine monthly usages between casual riders(Customer) and annual members(Subscriber) depending on years.\n",
    "\n",
    "<img src=\"Monthly_usage_2013.png\" width=50%><img src=\"Monthly_usage_2014.png\" width=50%>\n",
    "<img src=\"Monthly_usage_2015.png\" width=50%><img src=\"Monthly_usage_2016.png\" width=50%>\n",
    "<img src=\"Monthly_usage_2017.png\" width=50%><img src=\"Monthly_usage_2018.png\" width=50%>\n",
    "<img src=\"Monthly_usage_2019.png\" width=50%><img src=\"Monthly_usage_2020.png\" width=50%>\n",
    "<img src=\"Monthly_usage_2021.png\" width=50%><img src=\"Monthly_usage_2022.png\" width=50%>\n",
    "<img src=\"Usage_based_on_year.png\" width=80%>\n",
    "Findings:\n",
    "- The summertime is always the peak. It seems the purpose of usage is for vacations.\n",
    "- From 2013 to 2015, we can see a steady increase in both usertype usages. However, the number of casual riders gets decreased after that. Similarly, the number of casual riders also get decreased in 2017.\n",
    "- After 2020, we can see the company changed its marketing strategy which targeted a new customer. The result is a steep increase in casual riders and a steep decrease in annual members. However, in 2021, both of the usertypes have a huge increase. During the summertime, we even can see that more casual riders use this service than annual riders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we analyze usage on each day of the week.\n",
    "<img src=Usage_of_Dayofweek.png width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    "- As we can see, casual riders use the service on the weekend, while annual members use the service on the weekdays.\n",
    "- Casual rider usage has a slight decrease from Saturday to Wednesday, and it starts to increase on Saturday. From Friday to Saturday, there is a huge jump.\n",
    "- Annual rider usage increase gradually from Monday to Tuesday, and then it starts decreasing toward Sunday, especially from Friday to Saturday. \n",
    "- We can assume simply that casual riders use the service for weekend trips, whereas annual members use the service for commuting to schools or work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2013\n",
    "\n",
    "<img src=2013_start_map.png width=50%><img src=2013_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014\n",
    "\n",
    "<img src=2014_start_map.png width=50%><img src=2014_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2015\n",
    "\n",
    "<img src=2015_start_map.png width=50%><img src=2015_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2016\n",
    "\n",
    "<img src=2016_start_map.png width=50%><img src=2016_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2017\n",
    "\n",
    "<img src=2017_start_map.png width=50%><img src=2017_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018\n",
    "\n",
    "<img src=2018_start_map.png width=50%><img src=2018_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019\n",
    "\n",
    "<img src=2019_start_map.png width=50%><img src=2019_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020\n",
    "\n",
    "<img src=2020_start_map.png width=50%><img src=2020_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2021\n",
    "\n",
    "<img src=2021_start_map.png width=50%><img src=2021_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022\n",
    "\n",
    "<img src=2022_start_map.png width=50%><img src=2022_end_map.png width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    "- Both usertype dock a bicycle at a station from the close station where they ride on a bicycle.\n",
    "- Casual riders mainly ride on bicycles around the airport, the beach and the museum, whereas annual members ride on a bicycle around main stations, the business district and the university. \n",
    "- Although the five most frequently used start stations and end stations for both usertypes look very similar and close, stations used by annual members look dense. Annual members use stations spreadly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will take a look at the length of riding time between two user types.\n",
    "\n",
    "<img src=\"Compare_Tripduration.jpg\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings:\n",
    "- Casual riders trip in the much longer distance than annual riders do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Act**\n",
    "What can be suggested based on the above observaions?\n",
    "\n",
    "First, let's revisit the key business task: *How do casual riders and annual members use their rental bikes differently?*\n",
    "\n",
    "According to the observation, I conclude:\n",
    "- They both have the peak of usage from both usertypes during the summertime, but the peak of annual riders is slightly later.\n",
    "This can indicate that some use the service as casual riders first, and then switch to annual members after they experience this.\n",
    "- Annual members seem to rent bicycles for commuting purposes because of the weekday usage, while casual riders rent bicycles for sightseeing or travelling through Chicago on the weekends. \n",
    "- Annual members rent bicycles from and stop bicycles at bike stations around train stations or the university, whereas casual riders frequently use stations around the airport, beaches, parks, or museums. This also supports the usage assumption of both users stated before. \n",
    "- Casual riders travel much longer distance compared to annual riders.\n",
    "\n",
    "Suggestions:\n",
    "- During the summertime, we can introduce a discount campaign and reduce each ride fee for a casual rider to attract more new customers. Also, we can have a summer trial campaign to let customers experience the benefit of having the membership over casual riders. Attracting more new customers and letting them experience the benefits of the membership can successfully convert some into annual members.\n",
    "- Since casual riders rent a bike on the weekends hugely, this company can provide another flexibility in the service, which is \"the weekend membership.\" To make this look more attractive, we can raise the fee of each ride for casual riders so that those users would feel \"maybe it is better to join in the weekend membership\" and switch to the membership.\n",
    "- Having advertisements around the airport about this service and the convenience of talking about how long it will take to each landmark by bicycle can increase the potential of those tourists renting a bicycle. On the other hand, the company put advertisements about how beneficial having the membership is over casual rides around universities and train stations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a54a4f96a192e48ee2064855e05e452f1b7735ee6d18d92e02fe1f7e00027b5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
